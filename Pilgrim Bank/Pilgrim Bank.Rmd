---
title: "Analisi Pilgrim Bank - Tesina"
author: "Luca Bajardi e Francesca Collini"
date: "31/07/2020"
output:
  pdf_document: default
  word_document: default
---
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduzione
Utilizziamo il dataset fornito dalla "Harvad Business School" relativo alla redditività di alcuni clienti nella Pilgrim Bank nel corso degli anni 1999 e 2000. 

Inizialmente, cerchiamo di predire il profitto di un cliente in base alle sue caratteristiche anagrafiche, questa analisi potrebbe essere utile per la banca nel caso in cui debba decidere ad esempio se concedere un prestito oppure no. Vorrei quindi una previsione molto accurata in modo da capire se quel determinato cliente sarà in grado di restituire il denaro e scegliere quelle azioni finanziarie che siano il meno rischiose possibile. Nella previsione è importante tenere conto del fatto che potrebbero mancare alcune informazioni relative ai clienti, in questo caso è necessario scegliere il modo opportuno per cercare di non buttare via quei dati, ma utilizzarli comunque per la nostra previsione.

Un altro tipo di analisi che vogliamo effettuare è quella nel tempo. Infatti, per ciascun cliente che è presente nella base dati nel 1999, abbiamo un'informazione sull'anno successivo: sappiamo se il cliente decide di lasciare la banca oppure di rimanerci e in quest'ultimo caso conosciamo anche il suo profitto in quell'anno. Quindi l'obiettivo della nostra analisi è quello di riuscire a prevedere se un cliente rimarrà fedele alla banca o meno. Per farlo, utilizziamo diversi metodi di classificazione tra questi l'albero di decisione e il knn. Inoltre poiché la variabile target alla quale siamo interessati è binaria, possiamo utilizzare anche la regressione logistica e l'svm. 

Infine ci concentriamo sull'eventuale passaggio di un cliente dal servizio offline a quello online. Se riuscissimo a  capire che, per una determinata tipologia di clienti, il passaggio al canale online, permette di guadagnare maggiormente, la banca potrebbe ad esempio portare avanti delle campagne pubblicitarie per fare in modo che i clienti scelgano l'opzione più profittevole. Per ottenere questo tipo di informazione, applichiamo un algoritmo di clustering (il k-means) considerando solamente quei clienti che nel 1999 utilizzavano il servizio di banca offline e che nel 2000 sono rimasti clienti della banca. All'interno di ogni cluster poi, calcoliamo la media, separatamente per coloro che hanno scelto di passare al digitale e per quelli che sono rimasti con il servizio standard. In questo modo riusciamo a definire delle tipologie di clienti e capire se per la banca risulta più o meno vantaggioso far passare il cliente alla banca online.


## Esplorazione dei dati
Carichiamo i dati leggendo il file csv e settiamo il seme del generatore pseudo-casuale così da avere i risultati sempre uguali.
```{r read}
rm(list =ls())
set.seed(1)
Pilgrim = read.csv(file = "PilgrimABC.csv", header=T)
attach(Pilgrim)
```

Osserviamo che il nostro dataset contiene 31634 osservazioni e 11 variabili (anche se le ultime due non sono interessanti ai fini della nostra analisi). I dati sono relativi a due anni, 1999 e 2000, per ciascuno di essi, abbiamo a disposizione un'informazione relativa al profitto (o alla perdita) di un determinato cliente in quell'anno e un'informazione che ci dice se quel cliente in quell'anno ha utilizzato l'opzione di online banking oppure no: la variabile Online quindi è una variabile binaria. Abbiamo poi a dispozione altre informazioni relative all'anagrafica del cliente:

* AGE: variabile categorica che indica a che fascia  di età appartiene il cliente (1 = less than 15 years; 2 = 15-24 years; 3 = 25-34 years; 4 = 35-44 years; 5 = 45-54 years; 6 = 55-64 years; 7 = 65 years and older.)

* INCOME: variabile categorica che indica il range del reddito di ciascun cliente (1 = less than $\$15,000; 2 = \$15,000-\$19,999; 3 = \$20,000-\$29,999; 4 = \$30,000-\$39,999; 5 = \$40,000- \$49,999; 6 = \$50,000-\$74,999; 7 = \$75,000-\$99,999; 8 = \$100,000-\$124,999; 9 = \$125,000$ and more.)

* TENURE: variabile quantitativa continua che rappresenta l'età di servizio.

* DISTRICT: variabile categorica che indica una delle tre regioni geografiche in cui si trova il cliente.
```{r esplorazione}
dim(Pilgrim)
names(Pilgrim[, 1:9])
```
Rinominiamo le colonne per evitare problemi con i nomi:
```{r rinomino_colonne}
Profit=Pilgrim$X9Profit
Online=Pilgrim$X9Online
Age=Pilgrim$X9Age
Income=Pilgrim$X9Inc
Tenure=Pilgrim$X9Tenure
District=Pilgrim$X9District
```

Stampiamo le prime righe del dataset per avere un'idea più chiara dei dati che abbiamo a disposizione. 
```{r dataset}
head(Pilgrim)
```

Dal summary del profitto possiamo facilmente osservare che la distribuzione è molto asimmetrica perchè media e mediana sono molto diverse tra loro. Inoltre notiamo che tutto il primo quartile è negativo, quindi c'è un numero abbastanza rilevante di persone che fa perdere soldi alla banca.
```{r summary profit}
summary(Profit)
```
Anche dall'istogramma sul profitto nel 1999, possiamo notare che c'è un discreto numero di clienti che mi fa perdere e che l'istogramma è molto scodato a destra quindi ci sono pochissimi clienti che mi fanno guadagnare molto.
```{r hist profit}
hist(Profit)
```
Possiamo notare che ci sono solo 16832 clienti che generano profitto sulle 31634 osservazioni presenti nel dataset.
```{r profitable}
N=length(Profit)
Nprofitable = sum(Profit>0)
cat('profitable = ', Nprofitable, ' out of ', N, '\n')
```
Tramite la curva di Pareto possiamo confermare che poche persone fanno guadagnare tanto, mentre la maggior parte delle persone fa guadagnare poco o addirittura fa perdere guadagno.
```{r Pareto curve}
cumprofit=cumsum(sort(Profit,decreasing=TRUE))*100/sum(Profit)
plot(100*(1:N)/N,cumprofit,type='l')
grid()
```

## Online vs Offline
Dall'analisi dei profitti medi possiamo notare che il profitto generato da chi utilizza i servizi online è maggiore rispetto a chi li utilizza offline.
```{r mean profits}
cat('average profit ', mean(Profit), '\n')
ProfitOnline = Profit[Online==1]
cat('average profit ON', mean(ProfitOnline), '\n')
ProfitOffline = Profit[Online==0]
cat('average profit OFF', mean(ProfitOffline), '\n')
```
Quello che vorremmo capire è se questa differenza è statisticamente significativa, quindi se davvero coloro che utilizzano i servizi online mi permettono di guadagnare di più. Per questo motivo, possiamo eseguire un `t.test` sulle due popolazioni, i clienti che utilizzano il servizio online e coloro che non lo usano, per andare a vedere quanto vale il p-value. L'ipotesi nulla in questo caso è che le medie siano uguali e che quindi la differenza tra le medie delle due popolazioni non sia significativa.
Analizziamo inoltre l'intervallo di confidenza per vedere se i dati sono sufficienti o no. Infatti se intervallo fosse troppo grande vorrebbe dire che avrei bisogno di più clienti per formulare una teoria generale.
```{r int.conf}
cat('Conf int profit ', t.test(Profit)$conf.int, '\n')
cat('p-value difference ',t.test(ProfitOnline,ProfitOffline)$p.value, '\n')
```
Risulta esserci una differenza di circa 6 dollari tra le due popolazioni, quindi non risulta più di tanto significtiva dal lato business, ma anche il p-value è maggiore di 0.05 e quindi possiamo concludere che questa differenza non è significativa nemmeno dal punto di vista statistico. In conclusione non possiamo rifiutare l'ipotesi nulla sulla differenza tra le medie.

Possiamo ottenere lo stesso risultato impostando il modello di regressione classico, utilizzando la variabile `Online` per prevedere la variabile `Profit`:
```{r lm_online}
mod = lm(Profit ~ Online)
summary(mod)
```
Dal summary del modello, possiamo osservare che il valore dell'intercetta è la media del profitto tra coloro che operano offline, mentre il valore aggiunto di quelli che operano online è di quasi 6 dollari come la differenza tra la media di quelli che operano online e la media di quelli che operano offline. Anche in questo caso però, il p-value è superiore a 0.05 come in precedenza. Questo significa che la variabile `Online` non è significativa. Tuttavia, questo potrebbe essere dovuto al fatto che stiamo mettendo insieme clienti molto diversi tra loro e quindi considerando un unico modello non riusciamo a distinguere bene i singoli effetti. Per questo introduciamo l'età nel modello di regressione.

## Age

La variabile `Age` è riconosciuta numerica anche se in realtà è categorica. Nell'analisi dobbiamo trasformarla in `factor` perché altrimenti vi è troppa influenza dell'ordinamento delle variabili categoriali.

```{r age factor}
Age1 = as.factor(Age)
summary(Age1)
```
Possiamo notare che ci sono 8289 osservazioni in cui non è presente l'età, infatti nel `summary` sottostante possiamo notare che nonostante ci siano 32 mila osservazioni ci sono solo 23 mila gradi di libertà in quanto quelle con i missing values sono eliminate automaticamente.
```{r lm_onlineAge1}
mod = lm(Profit ~ Online+Age1)
summary(mod)
```
Ora sulle fasce d'età vi è una significatività sia statistica che di business, infatti le diverse età potrebbero implicare diversi redditi, in linea generale un giovane tende ad usare di più l'online banking ma ha un reddito minore e quindi fa guadagnare di meno.

Posso notare che a prescindere dall'utilizzo dell'online o dell'offline i giovani sono meno profittevoli degli anziani:
```{r check profitability}
lapply(split(Profit,as.factor(Age)),mean) 
```
Inoltre il $20\%$ dei giovani usa l'online, invece questa percentuale scende per le fasce di età successive fino ad arrivare a poco più del $3\%$.
```{r lm_onlineAge3}
lapply(split(Online,as.factor(Age)),mean)
```

Ci potrebbe essere un bias dovuto ai dati mancanti. Infatti ci sono molte osservazioni in cui non abbiamo l'informazione sull'età. Non sappiamo perchè questi dati siano mancanti, anche se è difficile pensare che il motivo sia semplicemente collegato a delle dimenticanze o sviste in fase di racconta dei dati. Probabilmente avrebbe più senso pensare ai conti cointestati oppure al fatto che il conto venga intestato ad una società. 

Proviamo ora a formulare un modello di regressione introducendo una variabile binaria che indica se abbiamo o meno a disposizione l'informazione sull'età:
```{r lm_onlineAgeGiven}
sum(is.na(Age))
AgeGiven = ifelse(is.na(Age),0,1) # 0 dove c'è NA, 1 se c'è l'età
mod = lm(Profit ~ AgeGiven)
summary(mod)
```
C'è una differenza statisticamente significativa sul profitto tra le osservazioni in cui è presente l'informazione sull'età e dove non c'è. La variabile `AgeGiven` infatti risulta significativa, la distribuzione tra le due popolazioni di conseguenza non risulta omogenea. Quindi, eliminando i dati dove manca l'età, stiamo distorcendo l'analisi, perchè queste medie sono "sporcate". Infatti c'è una profittabilità media più alta tra chi mi ha dato l'età rispetto a chi non me l'ha data.

### Rimpiazziamo i valori mancanti con il valore nullo
Possiamo provare diversi metodi per cercare di recuperare quelle osservazioni dove l'età non è presente, in modo da includerle comunque nell'analisi. Se avessimo delle righe complete ed alcune con un solo campo mancante, potremmo costruire un modello di regressione in modo da prevedere quel valore. Una possibile alternativa, più immediata, è quella di sostituire i valori mancanti con i valori nulli. Questa strada sembra abbastanza convincente, quando l'età è una variabile categorica e possiamo quindi scegliere un valore arbitrario. Quando invece la variabile è numerica non ha molto senso, perchè equivale a dire che coloro che non hanno fornito l'età, risultano neonati.
```{r lm_onlineAge4}
AgeZero = ifelse(is.na(Age),0,Age) 
table(AgeZero)
```
Andiamo a formulare un nuovo modello di regressione, utilizzando questa nuova variabile in cui abbiamo sostituito l'età nulla a coloro per i quali questa infromazione non è disponibile.
```{r lm_AgeZero}
mod = lm(Profit ~ Online+AgeZero)
summary(mod)
```
Anche se questa variabile risulta significativa, i valori dei coefficienti sono dovuti al fatto che, in modo arbitrario, abbiamo scelto di sostituire i valori  mancanti con il valore nullo.

### Rimpiazziamo i valori mancanti con la media
Una possibile alternativa è quella di sostituire i valori mancanti con la media dell'età calcolata sui valori presenti.
```{r AgeAverage}
mm = mean(Age, na.rm=TRUE)
AgeAverage = ifelse(is.na(Age),mm,Age)
table(AgeAverage)
```
```{r lm_AgeAverage}
mod = lm(Profit ~ Online+AgeAverage)
summary(mod)
```

Anche in questo caso, la variabile risulta significativa, ma ovviamente osserviamo che i valori dei coefficienti cambiano, ed in particolare cambia il contributo della variabile `Online`, quindi a seconda di come tappo il buco, di come scelgo di inserire i valori mancanti nel modello, otteniamo un risultato diverso. Questo ci suggerisce che probabilmente, non è questa la strada giusta per procedere.

Per tentare di evitare questo problema potremmo  considerare i modelli ottenuti tenendo conto sia della variabile `Age` opportunamente modificata, sia del fatto che la variabile `Age` venga fornita oppure no. Questo ci permette di considerare una variabile categorica che indica la presenza o meno dell'informazione sull'età, quindi non importa più di tanto come vado a rimepire il buco dell'informazione mancante.

```{r lm_AgeZero+Given}
mod = lm(Profit ~ Online+AgeZero+AgeGiven)
summary(mod)
```


```{r lm_AgeAverage+Given}
mod = lm(Profit ~ Online+AgeAverage+AgeGiven)
summary(mod)
```
Osserviamo che in entrambi i casi, tutte le variabili risultano significative perchè il p-value corrispondente è sufficientemente piccolo. Inoltre il valore della variabile `Online` è lo stesso del caso precedente anche se abbiamo scelto di tappare i buchi fissando dei valori arbitrari. Tuttavia il valore dell'$R^2$ risulta essere molto molto piccolo, quindi questo modello povero arriva a spiegare circa il $2.5\%$ della variabilità. 

## Income
Per cercare un modello più valido, possiamo considerare un'altra variabile, ad esempio il reddito di ciascun cliente. Anche in questo caso osserviamo che ci sono alcuni valori NA  e possiamo scegliere come includerli. Decidiamo per esempio di sostituire i valori mancnanti con quelli nulli.
```{r lm_IncomeZero}
IncomeZero = ifelse(is.na(Income),0,Income)
IncomeGiven = ifelse(is.na(Income),0,1)
mod = lm(Profit ~ Online+AgeAverage+AgeGiven+IncomeZero+IncomeGiven)
summary(mod)
```
Possiamo notare, che il valore della variabile Online scende un po' (passando da circa $19\$$ ad $11\$$ e che  l'$R^2$ è quasi raddoppiato, ma rimane comunque piccolo.

## Altri modelli di regressione
Notiamo che non ci sono valori mancanti nella variabile `District`, tuttavia viene considerata numerica, quindi vorremmo trasformarla in categorica, in modo che ogni valore venga associato ad uno dei tre distretti. Quello che possiamo fare è introdurre due variabili binarie che rappresentano i distretti. Notiamo inoltre che non ci sono valori mancanti neanche nella variabile `Tenure`.
```{r district}
any(is.na(District))
table(District) 
District1100 = ifelse(District==1100,1,0)
District1200 = ifelse(District==1200,1,0)
any(is.na(Tenure))
```
Andando ad effettuare la regressione con tutte queste variabili, notiamo che l'$R^2$ (e anche l'$R_{adj}^2$) sta aumentando anche se sempre di poco, mentre il contributo della variabile Online adesso vale circa $13\$$.
```{r regressione completa}
mod = lm(Profit ~ Online+AgeAverage+AgeGiven+IncomeZero+IncomeGiven+Tenure
          +District1100+District1200)
summary(mod)
```

### Age come variabile categorica
```{r AgeCat}
AgeCat = ifelse(is.na(Age)==TRUE,0,Age)
Age1=as.factor(AgeCat)
levels(Age1)
```
```{r lm_onlineAge5}
mod = lm(Profit ~ Online+Age1+IncomeZero+IncomeGiven+Tenure+District1100+District1200)
summary(mod)
```
Anche in questo caso l'$R^2$ continua a rimanere molto piccolo e molti livelli di `Age` non risultano neppure significativi.

### Income come variabile categorica
```{r IncomeCat}
IncomeCat = ifelse(is.na(Income)==TRUE,0,Income)
Income1=as.factor(IncomeCat)
levels(Income1)
```
```{r lm_income}
mod = lm(Profit ~ Online+Age1+Income1+Tenure+District1100+District1200)
summary(mod)
```

Anche in questo caso l'$R^2$ continua a rimanere molto piccolo e molti livelli di `Age` e di `Income` non risultano neppure significativi.

In conclusione, i modelli trovati sono poco utili nella previsione del profitto perchè non riescono bene a spiegare la varibilità presente.

# Profitto nel tempo
Possiamo provare a migliorare la situazione, utilizzando la storia della banca, e quindi anche le informazioni passate dei clienti.
```{r parte b}
#Rinominiamo le variabili
Profit9=X9Profit 
Online9=X9Online
Profit0=X0Profit
Online0=X0Online
Income=X9Inc
Age=X9Age
```


## Modello base
Proviamo a prevedere il profitto di ciascun cliente nel 2000, andando ad utilizzare l'informazione binaria riguardo all'uso dell'online banking. L'$R^2$ è troppo basso, quindi vorremmo migliorare questo modello.
```{r mod1}
mod1 = lm(Profit0 ~ Online9)
summary(mod1)
```

Per provare a far aumentare il valore dell'$R^2$, possiamo utilizzare non solo l'informazione della variabile `Online`, ma anche le caratteristiche anagrafiche a nostra disposizione relative al singolo cliente, quelle che abbiamo utilizzato nei modelli precedenti.

```{r mod2}
mod2 = lm(Profit0 ~ Online9+AgeZero+AgeGiven+IncomeZero+IncomeGiven+Tenure
           +District1100+District1200)
summary(mod2)
```
Questo migliora abbastanza le prestazioni, perchè così riusciamo a spiegare molta più della variabilità presente. Inoltre il modello potrebbe essere ulteriormente migliorato, infatti abbiamo a disposizione un'altra informazione sui singoli clienti: il profitto nel 1999.
```{r profit plot}
plot(Profit9, Profit0)
```
Inserendo questa informazione nel modello è come se dicessimo che il profitto nell'anno successivo dipende dal profitto dell'anno in corso e dalle caratteristiche del singolo cliente. Quindi in linea di principio, coloro che l'anno precdente mi hanno fatto guadagnare, continueranno a farmi guadagnare anche nell'anno successivo. 
```{r mod3}
mod3 = lm(Profit0 ~ Profit9+Online9+AgeZero+AgeGiven+IncomeZero+IncomeGiven+Tenure
           +District1100+District1200)
summary(mod3)
```
Adesso l'$R^2$ risulta notevolmente migliorato: riusciamo a spiegare oltre il $36\%$ della variabilità.

Possiamo anche supporre che alcuni dei dati anagrafici non siano rilevanti, ma magari non li abbiamo utilizzati nel modo giusto all'interno del modello. Infatti provando a tenere la variabile del profitto precedente come regressore, ma eliminando le variabili `Age` e `Income`, otteniamo un modello che spiega all'incirca la stessa variabilità.

```{r mod4}
mod4 = lm(Profit0 ~ Profit9+Online9+Tenure+District1100+District1200)
summary(mod4)
```


Quello che possiamo osservare è come le due variabili legate al profitto del singolo cliente nei diversi anni, siano correlate tra loro. Osserviamo infatti che c'è una correlazione di circa il $60\%$. Sono presenti inoltre solamente 8 osservazioni in cui il profitto nel 2000 risulta essere maggiore di 5000 e una osservazione con profitto nel 2000 minore di -5000, quindi possiamo pensare che quelle osservazioni siano degli outliers.
```{r profit}
cor(Profit9,Profit0,use="complete.obs")
sum(Profit0>5000,na.rm=TRUE)
sum(Profit0<(-5000),na.rm=TRUE)
```
Quello che possiamo fare è andare ad osservare il valore dell'$R^2$ nel caso in cui questi valori vengano eliminati, per capire se il modello risulta migliore.
```{r outliers, warning=FALSE}
c=which(abs(Profit0)>5000)
detach(Pilgrim)
data=Pilgrim[-c,]
attach(data)
Profit9=X9Profit
Online9=X9Online
Age=X9Age
Income=X9Inc
Tenure=X9Tenure
District=X9District
Profit0=X0Profit
Online0=X0Online
District1100 = ifelse(District==1100,1,0)
District1200 = ifelse(District==1200,1,0)
AgeGiven = ifelse(is.na(Age),0,1)
AgeZero = ifelse(is.na(Age),0,Age)
IncomeZero = ifelse(is.na(Income),0,Income)
IncomeGiven = ifelse(is.na(Income),0,1)
mod3 = lm(Profit0 ~ Profit9+Online9+AgeZero+AgeGiven+IncomeZero+IncomeGiven+Tenure
           +District1100+District1200)
summary(mod3)
mod4 = lm(Profit0 ~ Profit9+Online9+Tenure+District1100+District1200)
summary(mod4)
```
Quindi andando a ripetere il codice precedente, quando però eliminiamo gli outliers, miglioriamo l'$R^2$ che negli ultimi due modelli raggiunge oltre il $50\%$. Per questo motivo nelle successive analisi considereremo il dataset senza outliers.

# Retain
Quello che possiamo fare, è considerare una variabile aggiuntiva `Retain` che ci dice se il cliente rimane nella banca anche nell'anno successivo. A questo punto vorremmo capire come prevedere al meglio se un cliente rimane con la banca nell'anno successivo oppure no, questo potrebbe dipendere da tutte le caratteristiche del cliente.

Si considera che il cliente rimane nella banca se è presente il valore di `Profit0`.
```{r retain}
Retain = ifelse(is.na(Profit0),0,1)
mod1 = lm(Retain ~ Online9)
summary(mod1)
mod2 = lm(Retain ~ Online9+AgeZero+AgeGiven+IncomeZero+IncomeGiven+Tenure
           +District1100+District1200)
summary(mod2)
mod3 = lm(Retain ~ Profit9+Online9+AgeZero+AgeGiven+IncomeZero+IncomeGiven+Tenure
           +District1100+District1200)
summary(mod3)
hist(mod3$fitted,nclass=50, main ="Histogram of mod3")
```
Andare a considerare il valore dell'$R^2$ per valtutare la bontà del modello non è molto opportuno perchè stiamo prevedendo se il cliente rimane oppure no, quindi si tratta di una variabile binaria. Dall'istogramma possiamo facilmente dedurre che ci sono due gruppi abbastanza distinti, quindi quello che possiamo fare è fissare una certa soglia al di sopra della quale possiamo concludere che il cliente è sicuro, mentre al di sotto si trovano quei clienti che probabilmente il prossimo anno cambieranno la banca. Infatti ci sono due mode molto alte e sufficientemente lontane, mentre tra i valori di 0.7 e 0.8, troviamo una "zona grigia", dove la frequenza è molto bassa e i clienti sono abbastanza incerti. Inoltre saremmo interessati ad interpretare i valori dell'istogramma come delle probabilità, anche se ci sono dei valori più grandi di 1. Per questa ragione, è preferibile usare i metodi di classificazione che sono adatti a valori di risposta qualitativi.

## Analisi di Retain con Regressione logistica
Proviamo a prevedere il comportamento futuro di un cliente, utilizzando la regressione logistica.
```{r logistic}
glm.out = glm(Retain ~ Profit9+Online9+AgeZero+AgeGiven+IncomeZero+
  IncomeGiven+Tenure+District1100+District1200,family=binomial(logit))
summary(glm.out)
hist(glm.out$fitted.values,nclass=50, main="Histogram of Logistic Regression")
```
Questo metodo risulta molto veloce,in quanto si ferma dopo solo 5 iterazioni. Inoltre le diagnostiche del modello sono un po' diverse, notiamo che non abbiamo più a disposizione l'$R^2$, ma non cambia il senso generale, come osserviamo dall'istogramma.
```{r confronto}
plot(mod3$fitted, glm.out$fitted, xlab="Predicted OLS", ylab="Predicted logit")
```
I dati utilizzati per costruire questo modello non sono bilanciati e quindi questo non è ottimale. Per fare una previsione più accurata possiamo procedere con il bilanciamento del dataset.

# Bilanciamento dataset
Andando ad osservare la distribuzione della variabile Retain, notiamo che il dataset risulta molto sbilanciato, perchè solamente 5238 clienti decidono di lasciare la banca nell'anno successivo.
```{r bilanciamento dati1}
Retain = as.factor(Retain)
summary(Retain)
```
Per questo motivo è utile andare a bilanciare i dati mediante un oversampling:
```{r bilanciamento dati2,warning=FALSE, message=FALSE}
library(ROSE)
dim_data_balanced = max(sum(Retain==1),sum(Retain==0))*2
data_balanced_over <- ovun.sample(as.factor(Retain) ~ Profit9+Online9+AgeZero+AgeGiven
                                   +IncomeZero+IncomeGiven+Tenure+District1100
                                   +District1200, method = "over",
                                   N = dim_data_balanced)$data
```

Per analizzare meglio i vari algoritmi di classificazione dividiamo in due parti il dataset bilanciato, una parte per il training e una parte per la validazione del modello. In questo modo riusciamo anche a testare il modello su un insieme esterno rispetto a quello con cui abbiamo formulato il modello. Scegliamo arbitrariamente di utilizzare il $70\%$ dei dati per il training set e la restante parte per il test set.
```{r split,warning=TRUE, message=TRUE}
set.seed(1)
train = sample(1:nrow(data_balanced_over), nrow(data_balanced_over)*0.7)
df.train = data_balanced_over[train,]
df.test  = data_balanced_over[-train,]
target.train = df.train$Retain
target.test  = df.test$Retain
```

# Modelli di classificazione con dataset bilanciato

Per capire qual è il modello migliore per prevedere il comportamento futuro di un cliente, quindi per capire se il cliente rimarrà anche il prossimo anno oppure verrà perso, possiamo analizzare la confusion matrix e le misure ad essa collegate. Nel caso specifico, la variabile target è binaria (vogliamo prevedere se il cliente rimane nella banca anche il prossimo anno oppure no), quindi sono possibili solamente due tipi di errori: coloro che in realtà rimangono fedeli, ma utilizzando il modello, prevediamo che cambieranno, e questi possiamo definirli come "falsi negativi" (FN), o viceversa coloro che vengono predetti come clienti fedeli e poi l'anno successivo non saranno più clienti della nostra banca e questi sono i "falsi positivi" (FP). 
L'accuratezza di un classificatore si definisce come il rapporto tra le osservazioni predette correttamente e tutte le osservazioni, vorrei che questo valore fosse il più possibile vicino ad 1:
$$Accuracy=\frac{TN+TP}{TN+FN+TP+FP}$$
Una politica più scupolosa da parte della banca porterebbe a far pesare di più l'errore sui falsi positivi. Infatti nel caso in cui si trattasse di un cliente che mi fa guadagnare molto e prevedo che rimanga con me anche l'anno prossimo, anche se nella realtà non sarà così, non faccio nessuna azione. Invece vorrei riuscire a prevedere che probabilmente quel cliente è incerto, in modo da attuare delle strategie di marketing per convicerlo a rivalutare la sua decisione. In questo caso piuttosto che guardare al valore dell'accuratezza siamo più interessati ad altre misure:

* La PRECISIONE che rappresenta la percentuale di osservazioni predette positive corrette:
$$Precision=\frac{TP}{TP+FP}$$

* La RECALL che rappresenta invece la percentuale di osservazioni realmente positive che vengono classificate correttamente:
$$Precision=\frac{TP}{TP+FN}$$

* La SPECIFICITA' che rappresenta la percentuale di osservazioni negative che vengono effettivamente classificate come negative:
$$Specificity=\frac{TN}{TN+FP}$$

## Decision Tree

Un possibile modello di classificazione da utilizzare, è quello dell'albero di decisione. Questo è un grafo a forma di albero appunto, dove ogni nodo interno rappresenta un test su uno degli attributi, ed ogni ramo rappresenta il risultato di questo test. Quindi il cammino dalla radice fino ad una foglia, rappresenta una regola di classificazione, infatti ogni foglia è associata ad un'etichetta di classe. Il nodo alla radice rappresenta l'intera popolazione, l'algoritmo consiste nello scegliere il miglior attributo su cui fare lo split in modo che le osservazioni con lo stesso valore di quell'attributo vadano a formare dei sottoinsiemi distinti dagli altri. Questi step vengono ripetuti finchè non troviamo un nodo foglia in ogni ramo dell'albero. Nel nostro caso, impostiamo dei parametri diversi da quelli di default, in modo che l'albero non sia nè troppo specifico, nè troppo generico. Infine validiamo il modello sull'insieme di test. 


```{r decision tree, message=FALSE}
library(tree)
setup<-tree.control(nrow(df.train),mincut = 2, minsize = 6, mindev = 0.001)

tree.Pilgrim = tree(Retain ~ Profit9+Online9+AgeZero+AgeGiven+IncomeZero+IncomeGiven
                     +Tenure+District1100+District1200, data=df.train, control = setup)
tree.pred = predict(tree.Pilgrim, df.test, type="class", probability=TRUE)
library(caret)
cf = confusionMatrix(data = tree.pred, reference = target.test, mode = "prec_recall")
cf
```

## Logistic Regression
In alternativa possiamo utilizzare la regressione logistica, infatti la variabile da prevedere è binaria. In questo caso, invece di una funzione lineare, si utilizza la funzione logistica  in modo che l'output sia compreso tra 0 e 1:
$$f(x)=\displaystyle{\frac{e^x}{1+e^x}}$$
Utilizzando questa funzione, siamo in grado di collegare il logaritmo della probabilità della classe di default, in particolare il logaritmo dell'odds, con l'espressione lineare del modello di regressione:
$$\log \left(\frac{p}{1-p}\right)=\mathbb{\beta}^T \mathbf{X}+ \epsilon$$
Dall'istogramma notiamo che la distribuzione dei valori predetti, rimane molto simile a quella ottenuta con il modello lineare: sempre due picchi abbastanza distanti ed una zona intermedia, dove le frequenze sono piuttosto basse.
```{r logistic2, warning=FALSE, message=TRUE}
glm.out = glm(Retain ~ Profit9+Online9+AgeZero+AgeGiven+IncomeZero+
  IncomeGiven+Tenure+District1100+District1200, family=binomial(logit), data=df.train)
summary(glm.out)
hist(glm.out$fitted.values,nclass=50, main="Histogram of Logistic Regression")
pred=predict(glm.out, df.test, type="response")
logit.pred = rep(0, dim(df.test)[1])
logit.pred[pred > .5] = 1
logit.pred=factor(logit.pred,labels=c("1","0"))
cf = confusionMatrix(data = logit.pred, reference = target.test, mode = "prec_recall",
                      positive="1")
cf
specificity=specificity(logit.pred,target.test, positive="1")
cat('Specificity:',specificity, '\n')
```

## KNN
Un ulteriore modello che possiamo utilizzare è il KNN. Questo algoritmo necessita di un parametro K da fissare e che rappresenta il numero di vicini da considerare nella fase successiva. Dopodichè, per ogni osservazione si considerano le prime K osservazioni più vicine, tra queste si valuta qual è la classe più comune ed infine questa viene assegnata all'osservazione che stiamo etichettando. Dopo aver provato diversi valori di K, in modo da scegliere il miglior valore per cercare di massimizzare l'accuratezza, formuliamo il modello.
```{r knn tuning, warning=TRUE}
set.seed(1)
train.control=trainControl(method="repeatedcv", number=3, repeats=1)
fit=train(as.factor(Retain) ~ Profit9+Online9+AgeZero+AgeGiven+IncomeZero+IncomeGiven
           +Tenure+District1100+District1200,
           method="knn",
           tuneGrid=expand.grid(k=c(4,8,12,16)), 
           trControl=train.control, 
           metric="Accuracy",
           data=df.train)
fit
```
```{r knn}
library(class)
knn_pred <- knn(df.train,df.test, cl=target.train,k=4)
cf = confusionMatrix(data = knn_pred, reference = target.test, mode = "prec_recall")
cf
specificity=specificity(knn_pred,target.test, positive="1")
cat('Specificity:',specificity, '\n')
```

## SVM
Utilizzando infine il metodo del Support Vector Machines, l'obiettivo è quello di trovare un iperpiano in N-1 dimensioni (dove N è il numero di variabili che utilizziamo per prevedere) che riesca a separare le diverse osservazioni a seconda della variabile target binaria di appartenenza. I punti più vicini all'iperpiano prendono il nome di vettori di supporto e quello che vogliamo è fare in modo che la loro distanza dall'iperpiano, che viene definita "margine", sia la più grande possibile in modo da ridurre l'errore di misclassificazione per le nuove osservazioni. I due iperparametri da fissare sono il costo, che rappresenta il trade-off tra l'errore di classificazione e un confine di decisione regolare, e "gamma" che invece stabilisce qual è il peso massimo che una singola osservazione nel training può raggiungere.
Dopo aver provato diversi valori, scegliamo la coppia che minimizza l'errore. Per poter scegliere il valore ottimale dei parametri, estraiamo un sample dall'insieme di training, utilizzando il metodo dell'under sampling, in modo da accellare il processo.
```{r svm tuning, warning=FALSE}
library(e1071)
dim_data_balanced_under = min(sum(Retain==1),sum(Retain==0))*2
data_balanced_under <- ovun.sample(as.factor(Retain) ~ Profit9+Online9+AgeZero+AgeGiven
                                    +IncomeZero+IncomeGiven+Tenure+District1100
                                    +District1200, method = "under",N = dim_data_balanced_under)$data
set.seed(1)
train = sample(1:nrow(data_balanced_under), nrow(data_balanced_under)*0.7)
df.train=data_balanced_under[train,]
df.test = data_balanced_under[-train,]
target.train = df.train$Retain
target.under.test = df.test$Retain
g=c(-5, -3, 1)
c=c(-3,1)
svm_par=tune.svm(as.factor(Retain) ~ Profit9+Online9+AgeZero+AgeGiven+IncomeZero
                  +IncomeGiven+Tenure+District1100+District1200,
                  data=df.train, kernel="linear", gamma=10^g, cost=10^c,
                  scale=TRUE)
summary(svm_par)
```
A questo punto possiamo utilizzare i valori dei due parametri trovati precedentemente, utilizzando tutto l'insieme di training e valutare la nostra previsione sull'insieme test.
```{r svm,warning=TRUE}
svm_model=svm(as.factor(Retain) ~ Profit9+Online9+AgeZero+AgeGiven+IncomeZero+IncomeGiven
               +Tenure+District1100+District1200, data = df.train, kernel = "linear",
               cost = 10, gamma=1e-05, scale = TRUE)
svm_pred=predict(svm_model, df.test)
cf = confusionMatrix(data = svm_pred, reference = target.under.test, mode = "prec_recall")
cf
specificity=specificity(svm_pred,target.under.test, positive="1")
cat('Specificity:',specificity, '\n')
```

# Confronto tra modelli di classificazione
Un utile modo per confrontare la performance di un modello per un classificatore binario, sono la curva ROC e l'area sotto di essa (AUC). La ROC plotta 1 meno la specificità e la recall (o sensitività), quindi il modello migliore è quello che ha un AUC più vicino ad 1.
```{r roc, message=FALSE,warning=FALSE}
library(pROC)
treeROC = roc(target.test,factor(tree.pred, ordered = TRUE), plot=TRUE, print.auc=TRUE,
               col="blue")
logit_roc=plot.roc(target.test, factor(logit.pred, ordered = TRUE), add=TRUE,
                    col="green", print.auc=TRUE, print.auc.y=0.3)
knn_roc = plot.roc(target.test,factor(knn_pred, ordered = TRUE), add=TRUE,
                    col="red", print.auc=TRUE, print.auc.y=0.7, print.auc.x=0.2)
svm_roc = plot.roc(target.under.test,factor(svm_pred, ordered = TRUE), add=TRUE,
                    col="magenta", print.auc=TRUE, print.auc.y=0.9, print.auc.x=0.1)
legend("bottomleft", legend = c("Logistic Regression", "Decision Tree", "KNN", "Svm"),
        col=c("green", "blue", "red", "magenta"), pch=15, cex=0.4)
```

Possiamo quindi concludere che il modello che ci dà la migliore previsione relativa al comportamento futuro dei clienti è il KNN, con una precisione e una specificità entrambe oltre il $90\%$.

# Clustering
Ora, dal dataset senza outliers, consideriamo solo coloro che nel 1999 erano offline (`Online9=0`) e che sono rimasti clienti nel 2000 (`Retain=1`). Inoltre creiamo delle variabili binarie che indicano la fascia d'età e di reddito alla quale ciascun cliente appartiene. Infine discretizziamo la variabile `Tenure`, che rappresenta gli anni di servizio, utilizzando altre variabili categoriche. In questo modo, siamo in grado di avere tutte le informazioni relative ad un cliente, escluso il profitto, attraverso delle variabili binarie.
```{r new dataset, message=FALSE,warning=TRUE}
detach(data)
newdata = data[Online9==0 & Retain==1,]
attach(newdata)
Profit9=X9Profit

Profit0=X0Profit
Online0=X0Online

District=X9District
District1100 = ifelse(District==1100,1,0)
District1200 = ifelse(District==1200,1,0)

Age=X9Age
Age1 = ifelse(Age==1&!is.na(Age),1,0)
Age2 = ifelse(Age==2&!is.na(Age),1,0)
Age3 = ifelse(Age==3&!is.na(Age),1,0)
Age4 = ifelse(Age==4&!is.na(Age),1,0)
Age5 = ifelse(Age==5&!is.na(Age),1,0)
Age6 = ifelse(Age==6&!is.na(Age),1,0)
Age7 = ifelse(Age==7&!is.na(Age),1,0)

Income=X9Inc
Income1 = ifelse(Income==1&!is.na(Income),1,0)
Income2 = ifelse(Income==2&!is.na(Income),1,0)
Income3 = ifelse(Income==3&!is.na(Income),1,0)
Income4 = ifelse(Income==4&!is.na(Income),1,0)
Income5 = ifelse(Income==5&!is.na(Income),1,0)
Income6 = ifelse(Income==6&!is.na(Income),1,0)
Income7 = ifelse(Income==7&!is.na(Income),1,0)
Income8 = ifelse(Income==8&!is.na(Income),1,0)
Income9 = ifelse(Income==9&!is.na(Income),1,0)

Tenure=X9Tenure
Tenure1 = ifelse(Tenure<10,1,0)
Tenure2 = ifelse(Tenure>=10&Tenure<20,1,0)
Tenure3 = ifelse(Tenure>=20&Tenure<30,1,0)
Tenure4 = ifelse(Tenure>=30&Tenure<40,1,0)
```

Possiamo osservare che nel caso in cui in uno dei valori di `Age` mancasse l'informazione, ovvero compare NA, tutte le variabili `AgeX` assumono il valore 0, quindi questo indica un'altra classe. Stessa cosa accade per la variabile `Income` e quando il valore della variabile `Tenure` è maggiore o uguale a 40.

A questo punto, il nostro obiettivo è quello di applicare un algoritmo di clustering. Quindi vorremmo cercare di raggruppare i clienti che hanno delle caratteristiche simili, in modo da applicare delle politiche di business specifiche del gruppo, per capire quale sia la strategia migliore da applicare con ciascuna tipologia di cliente.

```{r clustering, message=TRUE,warning=TRUE}
set.seed(1)
num_tot_cluster = 25
df = data.frame(Age1, Age2, Age3, Age4, Age5, Age6, Age7, Income1, Income2, Income3, Income4, Income5, Income6, Income7, Income8, Income9, Tenure1, Tenure2, Tenure3, Tenure4, District1100, District1200)
k2 <- kmeans(df, centers = num_tot_cluster, nstart = 25)
```

Il metodo di clustering più conosciuto ed utilizzato per la sua immediatezza è il k-means. Per utilizzarlo, bisogna definire in anticipo qual è k, ovvero il numero finale di cluster che vogliamo formare. L'approccio è basato su un problema di ottimizzazione che consiste nel minimizzare la somma degli errori al quadrato data una specifica partizione. L'algoritmo consiste nel:

* Partire da una partizione arbitraria dove si scelgono k semi, uno per ogni cluster e ad ogni osservazione viene assegnato il cluster del seme più vicino.

* Selezionare un'osservazione ed eventualmente riassegnarla ad un altro cluster, se questa operazione migliora la qualità generale del cluster. La distanza va sempre calcolata dall'osservazione che stiamo considerando al centroide del cluster, che può essere aggiornato quando un nuovo elemento viene aggiunto al cluster.

* Ripetere finchè nessun miglioramento è possibile.

Nel caso specifico, consideriamo le variabili binarie relative all'età, al reddito, agli anni di servizio e al distretto di residenza, per formare 25 diversi cluster. All'interno di ciascun cluster andiamo a calcolare due diverse medie, quella per il clienti che sono rimasti Offline anche nel 2000 e coloro che invece in quest'anno sono passati al servizio della banca Online. In quei cluster in cui la differenza è positiva, vuol dire che in media guadagno di più quando il cliente decide di passare al canale online, quindi sarebbe utile portare avanti delle campagne pubblicitarie o applicare sconti per invogliare i clienti a cambiare. Anche se in realtà osserviamo che questa differenza in media non assume valori troppo grandi, la massima differenza è pari a 16 dollari, quindi bisogna tenere conto di questo aspetto quando si scegliarà se e quale strategia adottare.
```{r for cluster}
deltaProfit = Profit0-Profit9
deltaOnOff = rep(0,num_tot_cluster)
for(num_cluster in 1:num_tot_cluster) {
  deltaProfitOnline  = mean(deltaProfit[Online0[k2$cluster==num_cluster]==1])
  deltaProfitOffline = mean(deltaProfit[Online0[k2$cluster==num_cluster]==0])
  if(is.na(deltaProfitOnline)){deltaProfitOnline=0}
  if(is.na(deltaProfitOffline)){deltaProfitOffline=0}
  deltaOnOff[num_cluster] = deltaProfitOnline-deltaProfitOffline
}
sort(deltaOnOff, decreasing = TRUE)
```
